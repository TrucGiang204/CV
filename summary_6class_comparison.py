"""
T√≥m t·∫Øt so s√°nh m√¥ h√¨nh 6 classes - Kh·∫Øc ph·ª•c overfitting
Ph√¢n lo·∫°i phong c√°ch thi·∫øt k·∫ø n·ªôi th·∫•t
"""

def print_header(title):
    print(f"\n{'='*70}")
    print(f"{title:^70}")
    print(f"{'='*70}")

def print_section(title):
    print(f"\n{title}")
    print("-" * len(title))

print_header("KH·∫ÆC PH·ª§C OVERFITTING - 6 CLASSES PHONG C√ÅCH THI·∫æT K·∫æ N·ªòI TH·∫§T")

print_section("üéØ 6 CLASSES ƒê∆Ø·ª¢C CH·ªåN")
selected_classes = [
    "1. asian (Ch√¢u √Å)",
    "2. coastal (Ven bi·ªÉn)", 
    "3. industrial (C√¥ng nghi·ªáp)",
    "4. victorian (Victoria)",
    "5. scandinavian (B·∫Øc √Çu)",
    "6. southwestern (T√¢y Nam M·ªπ)"
]

for class_item in selected_classes:
    print(f"  {class_item}")

print_section("üö® V·∫§N ƒê·ªÄ C·ª¶A M√î H√åNH G·ªêC")
print("M√¥ h√¨nh g·ªëc 6 classes c√≥ th·ªÉ b·ªã OVERFITTING:")
print("  ‚Ä¢ S·ª≠ d·ª•ng EfficientNetB3 (qu√° ph·ª©c t·∫°p cho 6 classes)")
print("  ‚Ä¢ Input size l·ªõn: 360√ó360")
print("  ‚Ä¢ Dropout th·∫•p: 0.3")
print("  ‚Ä¢ Kh√¥ng c√≥ L2 regularization")
print("  ‚Ä¢ Fine-tune to√†n b·ªô base model")
print("  ‚Ä¢ Dense layer c√≥ 256 neurons (qu√° nhi·ªÅu cho 6 classes)")

print_section("‚úÖ GI·∫¢I PH√ÅP C·∫¢I TI·∫æN CHO 6 CLASSES")

print("\n1. GI·∫¢M MODEL COMPLEXITY (Quan tr·ªçng nh·∫•t):")
print("  ‚Ä¢ EfficientNetB3 ‚Üí EfficientNetB0")
print("  ‚Ä¢ Input size: 360√ó360 ‚Üí 224√ó224")
print("  ‚Ä¢ Dense layers: 256 ‚Üí 64 ‚Üí 32 neurons (ph√π h·ª£p 6 classes)")
print("  ‚Ä¢ Freeze nhi·ªÅu layers h∆°n (ch·ªâ fine-tune 15 layers cu·ªëi)")

print("\n2. REGULARIZATION M·∫†NH H∆†N:")
print("  ‚Ä¢ L2 Regularization: 0.01 cho Dense layers")
print("  ‚Ä¢ Dropout tƒÉng: 0.3 ‚Üí 0.5/0.4")
print("  ‚Ä¢ BatchNormalization sau m·ªói Dense layer")

print("\n3. DATA AUGMENTATION T·ªêI ∆ØU:")
print("  ‚Ä¢ RandomFlip horizontal")
print("  ‚Ä¢ RandomRotation: 0.3 (tƒÉng t·ª´ 0.1)")
print("  ‚Ä¢ RandomZoom: 0.3")
print("  ‚Ä¢ RandomContrast: 0.3 (m·ªõi)")
print("  ‚Ä¢ RandomBrightness: 0.3 (m·ªõi)")

print("\n4. TRAINING STRATEGIES:")
print("  ‚Ä¢ Class weights ƒë·ªÉ c√¢n b·∫±ng d·ªØ li·ªáu")
print("  ‚Ä¢ Early stopping: patience=10 (ph√π h·ª£p 6 classes)")
print("  ‚Ä¢ Learning rate reduction: factor=0.3")
print("  ‚Ä¢ Batch size: 32 (·ªïn ƒë·ªãnh h∆°n)")

print_section("üìä SO S√ÅNH D·ª∞ KI·∫æN")

print(f"{'Metric':<20} {'M√¥ H√¨nh G·ªëc':<18} {'M√¥ H√¨nh C·∫£i Ti·∫øn':<20} {'C·∫£i Thi·ªán':<15}")
print("-" * 75)
print(f"{'Model Size':<20} {'EfficientNetB3':<18} {'EfficientNetB0':<20} {'~70% nh·ªè h∆°n':<15}")
print(f"{'Input Size':<20} {'360√ó360':<18} {'224√ó224':<20} {'62% √≠t pixel':<15}")
print(f"{'Dense Neurons':<20} {'256':<18} {'64‚Üí32':<20} {'Ph√π h·ª£p h∆°n':<15}")
print(f"{'Dropout':<20} {'0.3':<18} {'0.5‚Üí0.4':<20} {'M·∫°nh h∆°n':<15}")
print(f"{'Regularization':<20} {'Kh√¥ng':<18} {'L2 (0.01)':<20} {'C√≥':<15}")
print(f"{'Training Time':<20} {'Ch·∫≠m':<18} {'Nhanh h∆°n':<20} {'~40% nhanh':<15}")
print(f"{'Memory Usage':<20} {'Cao':<18} {'Th·∫•p h∆°n':<20} {'~50% √≠t':<15}")

print_section("üìà K·∫æT QU·∫¢ D·ª∞ KI·∫æN CHO 6 CLASSES")

print("M√î H√åNH G·ªêC 6 classes (∆∞·ªõc t√≠nh):")
print("  ‚Ä¢ Training Accuracy: ~85-90%")
print("  ‚Ä¢ Validation Accuracy: ~70-75%")
print("  ‚Ä¢ Accuracy Gap: ~10-15% (overfitting)")
print("  ‚Ä¢ Test Accuracy: ~70-75%")

print("\nM√î H√åNH C·∫¢I TI·∫æN 6 classes (d·ª± ki·∫øn):")
print("  ‚Ä¢ Training Accuracy: ~80-85% (gi·∫£m do regularization)")
print("  ‚Ä¢ Validation Accuracy: ~78-83% (tƒÉng do generalization)")
print("  ‚Ä¢ Accuracy Gap: ~2-5% (gi·∫£m overfitting ƒë√°ng k·ªÉ)")
print("  ‚Ä¢ Test Accuracy: ~78-83% (t·ªët h∆°n)")

print_section("üéØ T·∫†I SAO 6 CLASSES D·ªÑ OVERFITTING H∆†N?")
reasons = [
    "‚Ä¢ √çt classes h∆°n ‚Üí Model d·ªÖ 'nh·ªõ' patterns",
    "‚Ä¢ M·ªói class c√≥ nhi·ªÅu samples h∆°n ‚Üí Risk overfitting cao",
    "‚Ä¢ Model ph·ª©c t·∫°p (B3) overkill cho 6 classes",
    "‚Ä¢ C·∫ßn regularization m·∫°nh h∆°n",
    "‚Ä¢ C·∫ßn gi·∫£m model capacity nhi·ªÅu h∆°n"
]

for reason in reasons:
    print(f"  {reason}")

print_section("üîß ƒêI·ªÄU CH·ªàNH ƒê·∫∂C BI·ªÜT CHO 6 CLASSES")

adjustments = [
    "‚úÖ Gi·∫£m Dense neurons m·∫°nh h∆°n: 256‚Üí64‚Üí32",
    "‚úÖ Freeze nhi·ªÅu layers h∆°n: ch·ªâ 15 layers cu·ªëi",
    "‚úÖ TƒÉng patience: 10 epochs (6 classes h·ªçc nhanh h∆°n)",
    "‚úÖ Class weights cho 6 classes c·ª• th·ªÉ",
    "‚úÖ Confusion matrix 6√ó6 d·ªÖ ph√¢n t√≠ch h∆°n",
    "‚úÖ Top-3 accuracy c√≥ √Ω nghƒ©a v·ªõi 6 classes"
]

for adj in adjustments:
    print(f"  {adj}")

print_section("üöÄ C√ÅCH S·ª¨ D·ª§NG")
print("1. Ch·∫°y m√¥ h√¨nh c·∫£i ti·∫øn 6 classes:")
print("   python improved_6class_interior_design_classifier.py")
print()
print("2. Script s·∫Ω t·ª± ƒë·ªông:")
print("   ‚Ä¢ T·∫°o dataset 6 classes t·ª´ dataset g·ªëc")
print("   ‚Ä¢ Split train/val/test cho 6 classes")
print("   ‚Ä¢ Train model v·ªõi anti-overfitting techniques")
print("   ‚Ä¢ ƒê√°nh gi√° v√† visualization")
print()
print("3. Files output:")
print("   ‚Ä¢ improved_6class_interior_design_model.keras")
print("   ‚Ä¢ best_6class_model.weights.h5")
print("   ‚Ä¢ training_results_6class.pkl")
print("   ‚Ä¢ confusion_matrix_6class_improved.png")

print_section("üìÅ C·∫§U TR√öC DATASET 6 CLASSES")
print("dataset_split_6class/")
print("‚îú‚îÄ‚îÄ train/")
print("‚îÇ   ‚îú‚îÄ‚îÄ asian/")
print("‚îÇ   ‚îú‚îÄ‚îÄ coastal/")
print("‚îÇ   ‚îú‚îÄ‚îÄ industrial/")
print("‚îÇ   ‚îú‚îÄ‚îÄ victorian/")
print("‚îÇ   ‚îú‚îÄ‚îÄ scandinavian/")
print("‚îÇ   ‚îî‚îÄ‚îÄ southwestern/")
print("‚îú‚îÄ‚îÄ val/")
print("‚îÇ   ‚îî‚îÄ‚îÄ (same structure)")
print("‚îî‚îÄ‚îÄ test/")
print("    ‚îî‚îÄ‚îÄ (same structure)")

print_section("üí° L·ª¢I √çCH C·ª¶A M√î H√åNH 6 CLASSES C·∫¢I TI·∫æN")

benefits = [
    "‚úÖ Ph√π h·ª£p v·ªõi s·ªë l∆∞·ª£ng classes (kh√¥ng overkill)",
    "‚úÖ Gi·∫£m overfitting ƒë√°ng k·ªÉ",
    "‚úÖ Training nhanh h∆°n nhi·ªÅu",
    "‚úÖ S·ª≠ d·ª•ng √≠t t√†i nguy√™n",
    "‚úÖ D·ªÖ deploy v√† maintain",
    "‚úÖ Accuracy t·ªët h∆°n tr√™n d·ªØ li·ªáu th·ª±c",
    "‚úÖ Confusion matrix d·ªÖ ph√¢n t√≠ch",
    "‚úÖ Ph√π h·ª£p cho production"
]

for benefit in benefits:
    print(f"  {benefit}")

print_section("‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG")

notes = [
    "‚Ä¢ Model nh·ªè h∆°n KH√îNG c√≥ nghƒ©a l√† k√©m h∆°n",
    "‚Ä¢ Training accuracy gi·∫£m l√† T√çCH C·ª∞C (√≠t overfitting)",
    "‚Ä¢ Validation accuracy tƒÉng l√† m·ª•c ti√™u ch√≠nh",
    "‚Ä¢ 6 classes d·ªÖ h·ªçc h∆°n ‚Üí c·∫ßn regularization m·∫°nh",
    "‚Ä¢ Monitor accuracy gap < 5% l√† t·ªët",
    "‚Ä¢ Test accuracy l√† metric quan tr·ªçng nh·∫•t"
]

for note in notes:
    print(f"  {note}")

print_header("üéâ M√î H√åNH 6 CLASSES T·ªêI ∆ØU!")

print("M√¥ h√¨nh c·∫£i ti·∫øn s·∫Ω:")
print("‚Ä¢ Ho·∫°t ƒë·ªông t·ªët h∆°n tr√™n 6 classes c·ª• th·ªÉ")
print("‚Ä¢ √çt overfitting h∆°n ƒë√°ng k·ªÉ")
print("‚Ä¢ Nhanh v√† hi·ªáu qu·∫£ h∆°n")
print("‚Ä¢ Ph√π h·ª£p cho ·ª©ng d·ª•ng th·ª±c t·∫ø")

print(f"\n6 Classes: asian | coastal | industrial | victorian | scandinavian | southwestern")

if __name__ == "__main__":
    print(f"\n{'='*70}")
    print("Script t√≥m t·∫Øt 6 classes ho√†n t·∫•t!")
    print("Ch·∫°y 'python improved_6class_interior_design_classifier.py' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    print(f"{'='*70}")